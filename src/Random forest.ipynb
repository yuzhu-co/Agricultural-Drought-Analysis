{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNqZx7QC/++z2mnLlLZLCN6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cqlzW4drT6u8"},"outputs":[],"source":["import pandas as pd\n","import os\n","from glob import glob\n","\n","# 设定文件夹路径\n","folder_path = \"/content/drive/MyDrive/RF/Processed_Seasonss/\"\n","\n","# 获取所有 CSV 文件路径\n","csv_files = glob(os.path.join(folder_path, \"*.csv\"))\n","\n","# 存储数据的列表\n","dataframes = []\n","\n","# 遍历所有文件\n","for file in csv_files:\n","    df = pd.read_csv(file)\n","\n","    # 删除 \"Additional_Data\" 列（如果存在）\n","    if \"Additional_Data\" in df.columns:\n","        df = df.drop(columns=[\"Additional_Data\"])\n","\n","    # 提取文件名作为 \"Province\" 信息，并清理字段\n","    province_name = os.path.basename(file).replace(\".csv\", \"\").replace(\"_Seasonal_Data\", \"\")\n","    df[\"Province\"] = province_name\n","\n","    # 修改 Season 列，去掉小数点\n","    df[\"Season\"] = df[\"Season\"].astype(str).str.replace(\".0\", \"\", regex=False)\n","\n","    dataframes.append(df)\n","\n","# 合并所有数据\n","merged_df = pd.concat(dataframes, ignore_index=True)\n","\n","# 保存合并后的数据\n","output_path = \"/content/drive/MyDrive/RF/Merged_Seasons_Cleaned.csv\"\n","merged_df.to_csv(output_path, index=False)\n"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import r2_score, mean_squared_error\n","import matplotlib.pyplot as plt\n","\n","# ============== 1. 读取数据 ==============\n","file_path = \"/content/drive/MyDrive/RF/Merged_Seasons_Cleaned.csv\"\n","df = pd.read_csv(file_path)\n","\n","# ============== 2. 明确目标与特征 ==============\n","# 目标变量：Drought_Index（你说它代表年产量）\n","target_col = \"Drought_Index\"\n","\n","# 如果你不需要 \"Season\"、\"Yield\" 作为特征，可以直接从特征列表中去掉\n","# 同时保留 Province 作为一个分类特征，或者也去掉，看你是否需要它\n","# 这里演示先把 Province 也保留下来，通过 one-hot 方式让模型识别省份差异\n","\n","drop_cols = [target_col, \"Season\", \"Yield\"]  # 这些列不作为特征\n","# 注意：如果 \"Yield\" 对你来说也是有用的信息，可以去掉它在这里的排除\n","\n","# 构造特征 X 和目标 y\n","X = df.drop(columns=drop_cols, errors='ignore')  # errors='ignore' 防止没有这些列时报错\n","y = df[target_col]\n","\n","# 查看当前特征列\n","print(\"特征列：\", X.columns.tolist())\n","\n","# ============== 3. 处理分类特征 (Province) ==============\n","# 如果 Province 存在并且是字符串，需要做 one-hot 编码，才能让随机森林识别\n","if \"Province\" in X.columns:\n","    X = pd.get_dummies(X, columns=[\"Province\"], drop_first=True)  # 防止虚拟变量陷阱\n","    # drop_first=True 表示少一个dummy，以避免共线性\n","\n","# ============== 4. 划分数据集 (70% 训练, 20% 验证, 10% 测试) ==============\n","X_train, X_temp, y_train, y_temp = train_test_split(\n","    X, y, test_size=0.3, random_state=42\n",")\n","# 这里 X_temp+y_temp 占 30%\n","# 再从 X_temp, y_temp 中分出 1/3 做测试(即0.1整体)\n","X_val, X_test, y_val, y_test = train_test_split(\n","    X_temp, y_temp, test_size=1/3, random_state=42\n",")\n","# 最终:\n","# X_train:70%  X_val:20%  X_test:10%\n","\n","print(f\"训练集: {X_train.shape}, 验证集: {X_val.shape}, 测试集: {X_test.shape}\")\n","\n","# ============== 5. 训练随机森林 (初步) ==============\n","rf = RandomForestRegressor(\n","    n_estimators=100,\n","    max_depth=None,\n","    random_state=42\n",")\n","rf.fit(X_train, y_train)\n","\n","# ============== 6. 超参数调优 (可选) ==============\n","param_grid = {\n","    \"n_estimators\": [50, 100, 200],\n","    \"max_depth\": [None, 10, 20],\n","    \"min_samples_split\": [2, 5, 10]\n","}\n","\n","grid_search = GridSearchCV(\n","    estimator=RandomForestRegressor(random_state=42),\n","    param_grid=param_grid,\n","    cv=3,  # 3折交叉验证\n","    scoring=\"r2\",  # 以R²为评分标准\n","    n_jobs=-1      # 并行加速\n",")\n","grid_search.fit(X_train, y_train)\n","\n","best_rf = grid_search.best_estimator_\n","print(\"最佳参数:\", grid_search.best_params_)\n","\n","# ============== 7. 在验证集和测试集上评估模型 ==============\n","def evaluate(model, X_data, y_data, dataset_name=\"Dataset\"):\n","    y_pred = model.predict(X_data)\n","    r2 = r2_score(y_data, y_pred)\n","    rmse = np.sqrt(mean_squared_error(y_data, y_pred))\n","    print(f\"{dataset_name} 评估: R²={r2:.3f}, RMSE={rmse:.3f}\")\n","    return r2, rmse\n","\n","print(\"\\n=== 验证集表现 ===\")\n","evaluate(best_rf, X_val, y_val, \"验证集\")\n","\n","print(\"\\n=== 测试集表现 ===\")\n","evaluate(best_rf, X_test, y_test, \"测试集\")\n","\n","# ============== 8. 特征重要性 ==============\n","feature_importances = best_rf.feature_importances_\n","feature_names = X_train.columns\n","\n","# 按重要性降序排序\n","sorted_idx = np.argsort(feature_importances)[::-1]\n","\n","# 如果特征很多，可以只画Top 10或Top 20\n","top_n = 10\n","top_idx = sorted_idx[:top_n]\n","plt.figure(figsize=(8, 6))\n","plt.barh(range(top_n), feature_importances[top_idx], align='center')\n","plt.yticks(range(top_n), [feature_names[i] for i in top_idx])\n","plt.gca().invert_yaxis()\n","plt.xlabel(\"Feature Importance\")\n","plt.title(\"Top {} Important Features\".format(top_n))\n","plt.show()\n"],"metadata":{"id":"ZdejZwb_cnZr"},"execution_count":null,"outputs":[]}]}